{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Assignment  37: Statistics Advance 6 - Utkarsh Gaikwad</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Assignment pdf link](13%20Mar_AssQ.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 1</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 : Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Variance (ANOVA) is a statistical method used to compare means between three or more groups. The method makes several assumptions about the data, which are important to consider when interpreting the results.\n",
    "\n",
    "### Assumptions of ANOVA:\n",
    "\n",
    "1. Independence: The observations within each group must be independent of each other. This means that the value of one observation should not influence the value of another observation within the same group.\n",
    "\n",
    "2. Normality: The distribution of the data within each group should be approximately normal. This means that the data should be symmetrically distributed around the mean and the majority of the data should be located near the mean.\n",
    "\n",
    "3. Homogeneity of variance: The variance within each group should be approximately equal. This means that the spread of the data should be similar across all groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violations of these assumptions can impact the validity of ANOVA results and should be carefully considered when interpreting the results. Examples of violations include:\n",
    "\n",
    "1. Independence: If there is a relationship between observations within a group, the assumption of independence is violated. For example, if the same individual is measured multiple times in a study, the observations within that individual are not independent.\n",
    "\n",
    "2. Normality: If the data is not normally distributed within each group, the ANOVA results may not be valid. For example, if the data is highly skewed, the normality assumption may be violated.\n",
    "\n",
    "3. Homogeneity of variance: If the variance is not approximately equal within each group, the ANOVA results may not be valid. For example, if the variance in one group is much larger than the variance in another group, the homogeneity of variance assumption may be violated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In summary, it is important to carefully consider the assumptions of ANOVA and to check for any violations before interpreting the results. If violations are found, alternative methods may need to be used to analyze the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 2</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 : What are the three types of ANOVA, and in what situations would each be used?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three types of ANOVA are :\n",
    "\n",
    "1. One-Way ANOVA: One-way ANOVA is a type of ANOVA that is used to compare the means of three or more groups that are classified by a single factor or independent variable. For example, a researcher might be interested in determining whether there are significant differences in the effectiveness of three different types of pain medication. The factor is the type of pain medication, and the dependent variable is the level of pain relief. One-way ANOVA is used to test whether there is a significant difference in the mean level of pain relief between the three types of pain medication.\n",
    "\n",
    "2. Repeated Measures ANOVA: Repeated measures ANOVA is a type of ANOVA that is used to compare the means of three or more groups when the same individuals are measured repeatedly over time or under different conditions. For example, a researcher might be interested in determining whether there are significant differences in the reaction time of participants when they are presented with different types of stimuli. The factor is the type of stimulus, and the dependent variable is the reaction time. Repeated measures ANOVA is used to test whether there is a significant difference in the mean reaction time between the different types of stimuli.\n",
    "\n",
    "3. Factorial ANOVA: Factorial ANOVA is a type of ANOVA that is used to compare the means of three or more groups when there are two or more independent variables or factors. For example, a researcher might be interested in determining whether there are significant differences in the effectiveness of a weight loss program that is targeted towards men and women. The factors are gender and weight loss program, and the dependent variable is the amount of weight lost. Factorial ANOVA is used to test whether there is a significant interaction between the gender and weight loss program factors, as well as the main effects of each factor on weight loss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ANOVA Types](https://statswork.com/blog/wp-content/uploads/2021/03/statwork2.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 3</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The partitioning of variance in ANOVA refers to the division of the total variation in a dataset into different sources of variation, which are then used to calculate the F-statistic and test for significant differences between groups. In ANOVA, the total variance is partitioned into two components: the variance between groups and the variance within groups.\n",
    "\n",
    "### The variance between groups represents the differences between the group means, and is calculated by taking the sum of squares between groups (SSB). The variance within groups represents the variability within each group, and is calculated by taking the sum of squares within groups (SSW). The total variance is calculated by taking the sum of squares total (SST), which is the sum of the squared differences between each data point and the overall mean.\n",
    "\n",
    "### By understanding the partitioning of variance in ANOVA, we can determine the proportion of the total variance that can be attributed to the differences between groups (SSB), and the proportion that is due to random error within each group (SSW). This allows us to test whether the differences between groups are statistically significant, and to determine the magnitude of these differences relative to the overall variability in the dataset. It also allows us to identify the sources of variation that are most important in explaining the differences between groups, and to assess the validity of our conclusions based on the assumptions underlying the ANOVA model.\n",
    "\n",
    "### In summary, understanding the partitioning of variance in ANOVA is important for interpreting the results of the analysis, identifying sources of variation that contribute to group differences, and evaluating the assumptions underlying the ANOVA model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![One Way Anova Variability](https://statistics.laerd.com/statistical-guides/img/partition-ss-ind.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 4</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of IRIS dataset : \n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "===================================================================\n",
      "\n",
      "Values for Sepal Length vs Species:\n",
      "SSE: 63.2121\n",
      "SSR: 38.9562\n",
      "SST: 102.1683\n",
      "\n",
      "===================================================================\n",
      "\n",
      "             df     sum_sq    mean_sq           F        PR(>F)\n",
      "species     2.0  63.212133  31.606067  119.264502  1.669669e-31\n",
      "Residual  147.0  38.956200   0.265008         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Loading Iris dataset from seaborn\n",
    "df_iris = sns.load_dataset('iris')\n",
    "print('Top 5 rows of IRIS dataset : ')\n",
    "print(df_iris.head())\n",
    "print('\\n===================================================================\\n')\n",
    "\n",
    "# Fit the one-way ANOVA model (sepal length vs Species)\n",
    "model = ols('sepal_length ~ species', data=df_iris).fit()\n",
    "\n",
    "# Calculate the sum of squares for the model\n",
    "print('Values for Sepal Length vs Species:')\n",
    "SSE = model.ess\n",
    "SSR = model.ssr\n",
    "SST = SSE + SSR\n",
    "\n",
    "print('SSE:', round(SSE,4))\n",
    "print('SSR:', round(SSR,4))\n",
    "print('SST:', round(SST,4))\n",
    "\n",
    "print('\\n===================================================================\\n')\n",
    "# Print the ANOVA table\n",
    "print(anova_lm(model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 5</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 : In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of Tooth Growth Dataset\n",
      "    len supp  dose\n",
      "0   4.2   VC   0.5\n",
      "1  11.5   VC   0.5\n",
      "2   7.3   VC   0.5\n",
      "3   5.8   VC   0.5\n",
      "4   6.4   VC   0.5\n",
      "\n",
      "==============================================================\n",
      "\n",
      "Main effects:\n",
      "C(supp)     205.350000\n",
      "C(dose)    2426.434333\n",
      "Name: sum_sq, dtype: float64\n",
      "\n",
      "==============================\n",
      "\n",
      "Interaction effect:\n",
      "C(supp):C(dose)    108.319\n",
      "Name: sum_sq, dtype: float64\n",
      "\n",
      "==============================\n",
      "\n",
      "ANOVA Table:\n",
      "                      sum_sq    df          F        PR(>F)\n",
      "C(supp)           205.350000   1.0  15.571979  2.311828e-04\n",
      "C(dose)          2426.434333   2.0  91.999965  4.046291e-18\n",
      "C(supp):C(dose)   108.319000   2.0   4.106991  2.186027e-02\n",
      "Residual          712.106000  54.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the inbuilt dataset from statsmodels\n",
    "data = sm.datasets.get_rdataset(\"ToothGrowth\", \"datasets\").data\n",
    "\n",
    "# printing top 5 rows of Tooth Growth dataset\n",
    "print('Top 5 rows of Tooth Growth Dataset')\n",
    "print(data.head())\n",
    "print('\\n==============================================================\\n')\n",
    "\n",
    "# Define the model formula\n",
    "model_formula = \"len ~ C(supp) + C(dose) + C(supp):C(dose)\"\n",
    "\n",
    "# Fit the model using OLS regression\n",
    "model = ols(model_formula, data).fit()\n",
    "\n",
    "# Calculate the main effects and interaction effects\n",
    "main_effects = sm.stats.anova_lm(model, typ=2)['sum_sq'][:2]\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=2)['sum_sq'][2:3]\n",
    "\n",
    "# Print the results\n",
    "print(\"Main effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\n==============================\\n\")\n",
    "print(\"Interaction effect:\")\n",
    "print(interaction_effect)\n",
    "print(\"\\n==============================\\n\")\n",
    "print(\"ANOVA Table:\")\n",
    "print(anova_lm(model,typ=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>len</td>       <th>  R-squared:         </th> <td>   0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 14 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>2.50e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:27:50</td>     <th>  Log-Likelihood:    </th> <td> -159.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    60</td>      <th>  AIC:               </th> <td>   330.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    54</td>      <th>  BIC:               </th> <td>   343.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                    <td>   13.2300</td> <td>    1.148</td> <td>   11.521</td> <td> 0.000</td> <td>   10.928</td> <td>   15.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(supp)[T.VC]</th>                <td>   -5.2500</td> <td>    1.624</td> <td>   -3.233</td> <td> 0.002</td> <td>   -8.506</td> <td>   -1.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dose)[T.1.0]</th>               <td>    9.4700</td> <td>    1.624</td> <td>    5.831</td> <td> 0.000</td> <td>    6.214</td> <td>   12.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dose)[T.2.0]</th>               <td>   12.8300</td> <td>    1.624</td> <td>    7.900</td> <td> 0.000</td> <td>    9.574</td> <td>   16.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(supp)[T.VC]:C(dose)[T.1.0]</th> <td>   -0.6800</td> <td>    2.297</td> <td>   -0.296</td> <td> 0.768</td> <td>   -5.285</td> <td>    3.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(supp)[T.VC]:C(dose)[T.2.0]</th> <td>    5.3300</td> <td>    2.297</td> <td>    2.321</td> <td> 0.024</td> <td>    0.725</td> <td>    9.935</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.336</td> <th>  Durbin-Watson:     </th> <td>   2.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.846</td> <th>  Jarque-Bera (JB):  </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.164</td> <th>  Prob(JB):          </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.852</td> <th>  Cond. No.          </th> <td>    9.77</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    len   R-squared:                       0.794\n",
       "Model:                            OLS   Adj. R-squared:                  0.775\n",
       "Method:                 Least Squares   F-statistic:                     41.56\n",
       "Date:                Tue, 14 Mar 2023   Prob (F-statistic):           2.50e-17\n",
       "Time:                        03:27:50   Log-Likelihood:                -159.35\n",
       "No. Observations:                  60   AIC:                             330.7\n",
       "Df Residuals:                      54   BIC:                             343.3\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================================\n",
       "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "Intercept                       13.2300      1.148     11.521      0.000      10.928      15.532\n",
       "C(supp)[T.VC]                   -5.2500      1.624     -3.233      0.002      -8.506      -1.994\n",
       "C(dose)[T.1.0]                   9.4700      1.624      5.831      0.000       6.214      12.726\n",
       "C(dose)[T.2.0]                  12.8300      1.624      7.900      0.000       9.574      16.086\n",
       "C(supp)[T.VC]:C(dose)[T.1.0]    -0.6800      2.297     -0.296      0.768      -5.285       3.925\n",
       "C(supp)[T.VC]:C(dose)[T.2.0]     5.3300      2.297      2.321      0.024       0.725       9.935\n",
       "==============================================================================\n",
       "Omnibus:                        0.336   Durbin-Watson:                   2.025\n",
       "Prob(Omnibus):                  0.846   Jarque-Bera (JB):                0.324\n",
       "Skew:                           0.164   Prob(JB):                        0.850\n",
       "Kurtosis:                       2.852   Cond. No.                         9.77\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 6</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 : Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance value is not given in above problem I am assuming significance value of alpha = 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the alpha value is 0.05 and the p-value is 0.02, then we can **REJECT the null hypothesis** at the 0.05 level of significance. This means that there is sufficient evidence to conclude that there is a statistically significant difference between the groups.\n",
    "\n",
    "### In this case, we would reject the null hypothesis, indicating that there is a significant difference between the groups. However, we still need to investigate the direction of this difference and which specific groups are different from each other.\n",
    "\n",
    "### The F-statistic of 5.23 suggests that there is a difference between the groups, and the magnitude of the F-value indicates that the variability between groups is 5.23 times the variability within groups. However, post-hoc tests or further analyses are necessary to determine which groups are significantly different from each other.\n",
    "\n",
    "### Post Hoc methods like Tukey's Honestly Significant Difference (HSD), Bonferroni correction, Scheffe's method can be used for further analysis of means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 7</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 : In a repeated measures ANOVA, how would you handle missing data, and what are the potentialconsequences of using different methods to handle missing data?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In repeated measures ANOVA, missing data can occur when one or more measurements are not available for a particular subject at a specific time point. There are several methods to handle missing data in repeated measures ANOVA, each with its own potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (CCA): This method involves excluding any participant with missing data from the analysis. CCA is easy to implement and can lead to unbiased estimates if data are missing at random. However, it can result in a loss of statistical power, and the assumption of missing completely at random (MCAR) may be violated.\n",
    "\n",
    "2. Last Observation Carried Forward (LOCF): This method involves using the last observed value of a variable as a substitute for any missing values for that variable at later time points. LOCF can produce biased estimates if the assumption that missing values are missing completely at random (MCAR) is not met.\n",
    "\n",
    "3. Multiple Imputation (MI): This method involves imputing missing values with plausible values, and then analyzing each of the completed datasets separately. MI can lead to unbiased estimates if data are missing at random (MAR) or missing not at random (MNAR), but it can be computationally intensive and requires making assumptions about the distribution of the missing data.\n",
    "\n",
    "4. Maximum Likelihood (ML): This method involves estimating model parameters using all available data and allowing for missing values. ML can lead to unbiased estimates if data are missing at random (MAR), but it requires making assumptions about the distribution of the missing data.\n",
    "\n",
    "### The choice of method for handling missing data in repeated measures ANOVA should depend on the reason for the missing data and the assumptions that can be made about the missingness mechanism. The potential consequences of using different methods to handle missing data can include biased estimates, loss of statistical power, and reduced generalizability of the findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 8</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 : What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc tests are used in ANOVA to compare specific pairs of groups after a significant main effect or interaction effect has been found. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test: This test compares all possible pairs of group means and controls for the family-wise error rate. It is often used when the number of groups is equal or large, and when there is no prior knowledge about which groups differ.\n",
    "\n",
    "2. Bonferroni correction: This test controls the family-wise error rate by dividing the alpha level by the number of comparisons. It is often used when there are few groups or when there is prior knowledge about which groups differ.\n",
    "\n",
    "3. Scheffe's test: This test also controls the family-wise error rate but is more conservative than Tukey's HSD test. It is often used when the number of groups is large, and when there is no prior knowledge about which groups differ.\n",
    "\n",
    "4. Dunnett's test: This test compares each group mean to a control group mean and controls for the family-wise error rate. It is often used when there is a control group and when the research question is focused on comparing other groups to the control group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The choice of post-hoc test depends on the research question, the number of groups, and the prior knowledge about which groups are likely to differ. A post-hoc test might be necessary when an ANOVA indicates a significant difference between groups but does not identify which specific groups differ. For example, a researcher might conduct an ANOVA to examine the effect of different instructional methods on student achievement. If the ANOVA shows a significant main effect of instructional method, the researcher might use a post-hoc test to compare the mean scores of each instructional method to identify which methods are significantly different from each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 9</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 : A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 57.06379442059458\n",
      "p-value: 4.561906121578302e-19\n",
      "We reject the null hypothesis.\n",
      "Conclusion : The mean weight loss is different for at least one diet.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate simulated data assuming normal distribution with same variance\n",
    "np.random.seed(1)\n",
    "diet_A = np.random.normal(5, 1, 50)\n",
    "diet_B = np.random.normal(4, 1, 50)\n",
    "diet_C = np.random.normal(3, 1, 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Null hypothesis: The mean weight loss is the same for all three diets.\n",
    "# Alternative hypothesis: The mean weight loss is different for at least one diet.\n",
    "null_hypothesis = \"The mean weight loss is the same for all three diets.\"\n",
    "alternate_hypothesis = \"The mean weight loss is different for at least one diet.\"\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {alternate_hypothesis}\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {null_hypothesis}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Tukey's test for mean difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B  -0.8278   0.0 -1.2477 -0.4079   True\n",
      "     A      C  -1.8898   0.0 -2.3097 -1.4699   True\n",
      "     B      C   -1.062   0.0 -1.4819 -0.6421   True\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#create DataFrame to hold data\n",
    "df = pd.DataFrame({'weight_loss': list(diet_A) + list(diet_B) + list(diet_C),\n",
    "                   'group': np.repeat(['A', 'B', 'C'], repeats=50)})\n",
    "\n",
    "# perform Tukey's test\n",
    "tukey = pairwise_tukeyhsd(endog=df['weight_loss'],\n",
    "                          groups=df['group'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "# Print results\n",
    "print(tukey)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above interpretation means all three means are different reject value is True for all of 3\n",
    "1. Mean Difference between diet_A and diet_B is -0.8278 \n",
    "2. Mean Difference between diet_A and diet_C is -1.8898\n",
    "3. Mean Difference between diet_A and diet_C is -1.062"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum mean difference is in between diet_A and diet_C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All mean differences with diet_A are negative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diet_A has shown highest weight loss compared to diet_B and diet_C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 10</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10 : A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming Significance level of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n======================================================================================\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the interpretations of the three conclusions:\n",
    "\n",
    "1. \"There is a significant main effect of software\": This means that the software programs used by the employees have a significant impact on the outcome variable (e.g., completion time), independent of the experience level of the employees. This suggests that the choice of software program is an important factor that should be considered carefully when completing this task.\n",
    "\n",
    "2. \"There is a significant main effect of experience\": This means that the experience level of the employees has a significant impact on the outcome variable, independent of the software program used. Specifically, this suggests that experienced employees may complete the task faster than novices, or vice versa. This finding can be helpful for the company to identify the best employees for a given task and to provide appropriate training for new employees.\n",
    "\n",
    "3. \"There is **NO significant** interaction effect between software and experience\": This means that the effect of software on the outcome variable does not depend on the experience level of the employees, and vice versa. This suggests that the software programs perform similarly for both novices and experienced employees. This finding can be helpful for the company to decide which software program to use, as they do not need to consider the experience level of the employees when making the choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 11</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11 : An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Two sample t-test , alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data for test_scores:\n",
      "   test_score    group\n",
      "0   70.079124  control\n",
      "1   70.780965  control\n",
      "2   68.814563  control\n",
      "3   69.387097  control\n",
      "4   66.185102  control\n",
      "\n",
      "===============================\n",
      "\n",
      "t-statistic: -28.5074, p-value: 3.096206271894725e-49\n",
      "\n",
      "\n",
      "Reject the Null Hypothesis\n",
      "Conclusion : There is SIGNIFICANT difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting numpy random seed\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generating normal test scores with same variance for both control groups\n",
    "test_score_control = np.random.normal(loc=70, scale=3, size=50)\n",
    "test_score_experimental = np.random.normal(loc=85, scale=3, size=50)\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame({'test_score':list(test_score_control)+list(test_score_experimental),\n",
    "                   'group':['control']*50 + ['experimental']*50})\n",
    "\n",
    "# printing the sample dataframe\n",
    "print('Simulated data for test_scores:')\n",
    "print(df.head())\n",
    "print('\\n===============================\\n')\n",
    "\n",
    "null_hypothesis = \"There is NO difference in test scores between the control and experimental groups.\"\n",
    "alt_hypothesis = \"There is SIGNIFICANT difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "# Conduct the two-sample t-test\n",
    "control_scores = df[df['group'] == 'control']['test_score']\n",
    "experimental_scores = df[df['group'] == 'experimental']['test_score']\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores, equal_var=True)\n",
    "print(f\"t-statistic: {t_stat:.4f}, p-value: {p_val}\")\n",
    "print('\\n')\n",
    "\n",
    "# Significance value \n",
    "alpha = 0.05\n",
    "if p_val<alpha:\n",
    "    print('Reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {alt_hypothesis}')\n",
    "else:\n",
    "    print('Failed to reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {null_hypothesis}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tukey's HSD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "control experimental  15.8829   0.0 14.7773 16.9886   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Conduct post-hoc Tukey's test\n",
    "tukey_results = pairwise_tukeyhsd(df['test_score'], df['group'], 0.05)\n",
    "print(tukey_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey's Results Interpretation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reject = True suggests that there is significant difference in both control and Experimental groups also p-adj is almost 0.\n",
    "\n",
    "2. Experimental group has increased the performance of test scores of students by mean of 15.88 approximately\n",
    "\n",
    "3. Mean score improved by Experimental method is (14.78,16.99) with 95% confidence level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 12</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12 : A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumed signifincance value of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "================================================\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n================================================\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of above\n",
    "\n",
    "1. In Repeated Measure ANOVA test we got p_value (Pr>F) as 0.0000 which is less than 0.05 .Reject the Null Hypothesis .Which means atleast one of the mean of groups is different.\n",
    "\n",
    "2. In Tukey's Post Hoc Test we get following interpretation :\n",
    "    * No significant difference between sales of Store A and Store B. Store B earns 21.24 dollars more than store A(becuse reject=False for this)\n",
    "    * Significant difference between sales of Store A and Store C . Store C has approx 207.8 dollars lesser compared to store A (reject=True)\n",
    "    * Siginficant difference between sales of Store B and Store C . Store C has approx 229.0 dollars lesser compared to store B (reject=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
